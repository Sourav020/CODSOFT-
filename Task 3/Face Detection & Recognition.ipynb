{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNWHf0FK5waKmV4/fLKccML"},"kernelspec":{"name":"ir","display_name":"R"},"language_info":{"name":"R"}},"cells":[{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0x6YZrrjRWLr","executionInfo":{"status":"ok","timestamp":1709559147444,"user_tz":-330,"elapsed":5315,"user":{"displayName":"Sourav Kundu","userId":"01924734281558427687"}},"outputId":"dfe2f179-108d-43aa-8664-952aca86a657"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: face_recognition in /usr/local/lib/python3.10/dist-packages (1.3.0)\n","Requirement already satisfied: face-recognition-models>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from face_recognition) (0.3.0)\n","Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.10/dist-packages (from face_recognition) (8.1.7)\n","Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.10/dist-packages (from face_recognition) (19.24.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from face_recognition) (1.25.2)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from face_recognition) (9.4.0)\n"]}],"source":["from posixpath import sep\n","!pip install face_recognition\n","from imutils import paths\n","import face_recognition\n","import pickle\n","import cv2\n","import os\n","\n","#get paths of each file in folder named Images\n","#Images here contains my data(folders of various person)\n","imagePaths = list(paths.list_images('/content/Elizabeth Olsen'))\n","knownEncodings = []\n","knownNames = []\n","# loop over the image paths\n","for (i, imagepath) in enumerate(imagePaths):\n","     # extract the person name from the image path\n","     name = imagePaths.split(os.path.sep) [-2]\n","     # load the input image and convert it from BGR (openCV ordering)\n","     # to dlib odering (RGB)\n","     image = cv2.cv2.imread(imagePaths)\n","     rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","     #Use Face_Recognition to locate faces\n","     boxes = face_recognition.face_location(rgb, model='hog')\n","     # compute the facial embedding for the face\n","     encodings = face_recognition.face_encodings(rgb, boxes)\n","     # loop over the encodings:\n","     for encoding in encodings:\n","          knownEncodings.append(encoding)\n","          knownNames.append(name)\n","\n",""]},{"cell_type":"code","source":["from google.colab.patches import cv2_imshow\n","import face_recognition_models\n","import face_recognition\n","import imutils\n","import pickle\n","import time\n","import cv2\n","import os\n","\n","#find path of xml file conataining haarcascade file\n","cascPathface = os.path.dirname(\n","cv2._file_) + \"/content/011.xml\"\n","# load the harcaascade in the cascade classifier\n","faceCascade = cv2.CascadeClassifier(cascPathface)\n","# load the known faces and embeddings saved in last file\n","data = pickle.loads(open('face_enc', \"rb\").read())\n","#Find path to the image you want to detect face and pass it here\n","image = cv2.imread(\"/content/011.jpg\")\n","rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","#convert image to Greyscale for haarcascade\n","gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","faces = faceCascade.detectMultiScale(gray,\n","                                     scaleFactor=1.1,\n","                                     minNeighbors=5,\n","                                     minSize=(60, 60),\n","                                     flags=cv2.CASCADE_SCALE_IMAGE)\n","# the facial embedding for face in input\n","encoding = face_recognition.face_encoding(rgb)\n","names = []\n","# loop over the facial embedding incase\n","# we have multiple embeddings for multiple faces\n","for encoding in encodings:\n","    #Compare encodings with encodings in data[\"encoding\"]\n","    #Matches contain array with boolean values and True for the embedding it matches closely\n","    ##set name -inknown if no encoding matches\n","    name = \"unknbwn\"\n","    # check to see if we have found a match\n","    if True in matches:\n","       #Find positions at which we get True and store them\n","       matchedIdxs = [i for (i, b) in enumerate(matches) if b]\n","       counts = {}\n","       # loop over the matched indexes and maintain a count for\n","       # each cecognized face face\n","       for i in matchedIdxs:\n","           #Check the names at respective indexes we stored in matched[dks\n","           name - data[\"names\"][i]\n","           #increase count for the name we got\n","           counts[name] = counts.get(name, 0)\n","           #set name which has highest count\n","           name = max(counts, key=counts.get)\n","\n","\n","        # update the list of names\n","        names.append(name)\n","        # loop over the recognized faces\n","        for ((x, y, w, h), name) in zip(faces, names):\n","            # rescale the face coordinates\n","            # draw the predicted face name on the image\n","            cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n","            cv2.putText(image, name, (x, y), cv2.FONT_HERSHEY_SIMPLEX,\n","             0.75, (0, 255, 0), 2)\n","    cv2_imshow(image)\n","    #cv2.waitkey(0)\n","\n","\n",""],"metadata":{"id":"dPdKFYwtqud4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"7j0j-dTQkQKz"},"execution_count":null,"outputs":[]}]}